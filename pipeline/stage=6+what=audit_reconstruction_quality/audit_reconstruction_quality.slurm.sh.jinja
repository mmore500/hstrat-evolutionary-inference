#!/bin/bash -login
########## Define Resources Needed with SBATCH Lines ##########
#SBATCH --time=4:00:00
#SBATCH --job-name audit_reconstruction_quality
#SBATCH --account=devolab
#SBATCH --output="/mnt/home/%u/slurm_job_log/a=audit_reconstruction_quality+slurm_job_id=%j+ext.txt"
#SBATCH --mem=12G
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=4
#SBATCH --mincpus=4
#SBATCH --nodes=1
#SBATCH --mail-type=FAIL
# No --mail-user, the default value is the submitting user
#SBATCH --exclude=csn-002,amr-250
# Job may be requeued after node failure.
#SBATCH --requeue

{{ setup_instrumentation }}

BATCH="{{ batch }}"
echo "BATCH ${BATCH}"

RUNMODE="{{ runmode }}"
echo "RUNMODE ${RUNMODE}"

REVISION="{{ revision }}"
echo "REVISION ${REVISION}"

{{ setup_production_dependencies }}

COLLAPSED_STAGE_PATH="${HOME}/scratch/data/hstrat-evolutionary-inference/runmode={{ runmode }}/stage=1+what=descend_template_phylogenies/"
echo "COLLAPSED_STAGE_PATH ${COLLAPSED_STAGE_PATH}"

RECONSTRUCTED_STAGE_PATH="${HOME}/scratch/data/hstrat-evolutionary-inference/runmode={{ runmode }}/stage=2+what=reconstruct_phylogenies/"
echo "RECONSTRUCTED_STAGE_PATH ${RECONSTRUCTED_STAGE_PATH}"

STAGE_PATH="${HOME}/scratch/data/hstrat-evolutionary-inference/runmode={{ runmode }}/stage=6+what=audit_reconstruction_quality/"
echo "STAGE_PATH ${STAGE_PATH}"

BATCH_PATH="${STAGE_PATH}/batches/${BATCH}/"
echo "BATCH_PATH ${BATCH_PATH}"

for try in {0..9}; do
  mkdir -p "${BATCH_PATH}" && break
  echo "mkdir -p ${BATCH_PATH} failed (try ${try})"
  SLEEP_DURATION="$((RANDOM % 10 + 1))"
  echo "sleeping ${SLEEP_DURATION} then retrying"
  sleep "${SLEEP_DURATION}"
done

for try in {0..9}; do
  ln -srfT "${BATCH_PATH}" "${STAGE_PATH}/latest" && break
  echo "ln -srfT ${BATCH_PATH} ${STAGE_PATH}/latest failed (try ${try})"
  echo "removing ${STAGE_PATH}/latest"
  rm -rf "${STAGE_PATH}/latest"
  SLEEP_DURATION="$((RANDOM % 10 + 1))"
  echo "sleeping ${SLEEP_DURATION} then retrying"
  sleep "${SLEEP_DURATION}"
done

NPROC="${SLURM_CPUS_ON_NODE-4}"
echo "NPROC ${NPROC}"

PYSCRIPT=$(cat << HEREDOC
import functools
import glob
import gzip
import io
import json
import logging
import math
import os
import random
import shutil
import sys

import alifedata_phyloinformatics_convert as apc
import dendropy as dp
from hstrat import _auxiliary_lib as hstrat_aux
from hstrat import hstrat
from keyname import keyname as kn
import numpy as np
import pandas as pd
from retry import retry
import tqdist
from tqdm import tqdm


logging.basicConfig(
    format="\n%(asctime)s %(levelname)-8s %(message)s\n",
    level=logging.INFO,
    datefmt=">>> %Y-%m-%d %H:%M:%S",
)

open_retry = retry(
  tries=10, delay=1, max_delay=10, backoff=2, jitter=(0, 4), logger=logging,
)(open)

__, reconstructed_path = sys.argv

logging.info(f"reconstructed_path {reconstructed_path}")

attrs = kn.unpack(kn.rejoin(reconstructed_path))

collapsed_directory = f"""${COLLAPSED_STAGE_PATH}/latest/epoch={
  int(attrs["epoch"])
}+resolution={
  int(attrs["resolution"])
}+treatment={
  int(attrs["treatment"])
}/"""
logging.info(f"collapsed_directory {collapsed_directory}")

@retry(
  tries=10, delay=1, max_delay=10, backoff=2, jitter=(0, 4), logger=logging,
)
def do_find_collapsed_path():
  for dirpath, subdirs, files in os.walk(collapsed_directory):
    for file in files:
      file = str(os.path.join(dirpath, file))
      logging.info(f"checking file {file}")
      if (
        int(
          kn.unpack(kn.rejoin(file))["replicate"]
        ) == int(attrs["replicate"])
      ) and kn.unpack(kn.rejoin(file))["ext"] == ".csv.gz":
        return file

collapsed_path = do_find_collapsed_path()
logging.info(f"collapsed_path {collapsed_path}")

@retry(
  tries=10, delay=1, max_delay=10, backoff=2, jitter=(0, 4), logger=logging,
)
def do_load_reconstructed_df():
  return pd.read_csv(reconstructed_path)
reconstructed_df = do_load_reconstructed_df()
logging.info(f"reconstructed_df loaded from {reconstructed_path}")

reconstructed_tree = apc.alife_dataframe_to_dendropy_tree(
  reconstructed_df, setup_edge_lengths=True,
)
logging.info(f"reconstructed_tree set up")

reconstructed_newick = reconstructed_tree.as_string(schema='newick').strip()
logging.info(f"""reconstructed_newick prepared with len {
  len(reconstructed_newick)
}""")

@retry(
  tries=10, delay=1, max_delay=10, backoff=2, jitter=(0, 4), logger=logging,
)
def do_load_collapsed_df():
  return pd.read_csv(collapsed_path)
collapsed_df = do_load_collapsed_df()
logging.info(f"collapsed_df loaded from {collapsed_path}")

collapsed_df["taxon_label"] = collapsed_df["loc"]
collapsed_tree = apc.alife_dataframe_to_dendropy_tree(
  collapsed_df, setup_edge_lengths=True,
)
logging.info(f"collapsed_tree set up")

collapsed_newick = collapsed_tree.as_string(schema='newick').strip()
logging.info(f"collapsed_newick prepared with len {len(collapsed_newick)}")

quartet_distance = tqdist.quartet_distance(
  reconstructed_newick, collapsed_newick
)
logging.info(f"quartet distance calculated as {quartet_distance}")

triplet_distance = tqdist.triplet_distance(
  reconstructed_newick, collapsed_newick
)
logging.info(f"triplet distance calculated as {triplet_distance}")

reconstruction_audit_records = [
  {
    **kn.unpack(kn.rejoin(reconstructed_path)),
    **{
      "triplet_distance" : triplet_distance,
      "quartet_distance" : quartet_distance,
    },
  }
]
logging.info("reconstruction_audit_records")
logging.info(str(reconstruction_audit_records))

reconstruction_audit_df = pd.DataFrame.from_records(
  reconstruction_audit_records
)
logging.info("reconstruction_audit_df")
logging.info(str(reconstruction_audit_df))

reconstruction_audit_filename = kn.pack({
  **kn.unpack(kn.rejoin(reconstructed_path)),
  **{
    "a" : "reconstruction-audit",
    "ext" : ".csv",
  },
})
reconstruction_audit_path = kn.chop(
  f"${BATCH_PATH}/"
  f"{reconstruction_audit_filename}",
  mkdir=True,
  logger=logging,
)
retry(
  tries=10, delay=1, max_delay=10, backoff=2, jitter=(0, 4), logger=logging,
)(
  # retry workaround
  lambda *args, **kwargs: reconstruction_audit_df.to_csv(*args, **kwargs),
)(reconstruction_audit_path, index=False)

provlog_path = f"{reconstruction_audit_path}.provlog.yaml"
@retry(
  tries=10, delay=1, max_delay=10, backoff=2, jitter=(0, 4), logger=logging,
)
def do_save():
  with open(provlog_path, "a+") as provlog_file:
    with open(f"{reconstructed_path}.provlog.yaml", "r") as src_provlog_file:
      provlog_file.write(src_provlog_file.read())
    with open(f"{collapsed_path}.provlog.yaml", "r") as src_provlog_file:
      provlog_file.write(src_provlog_file.read())

    provlog_file.write(
f"""-
  a: {provlog_path}
  batch: {{ batch }}
  date: $(date --iso-8601=seconds)
  hostname: $(hostname)
  revision: {{ revision }}
  runmode: {{ runmode }}
  user: $(whoami)
  uuid: $(uuidgen)
  slurm_job_id: ${SLURM_JOB_ID-none}
  stage: 6
  stage 6 batch path: $(readlink -f "${BATCH_PATH}")
  reconstructed_path: {reconstructed_path}
  collapsed_path: {collapsed_path}
""",
    )

do_save()

logging.info(f"wrote audit to {reconstruction_audit_path}")

logging.info("PYSCRIPT complete")
HEREDOC
)


TARGET_PHYLOGENY_FILES='{{ target_phylogeny_files }}'
echo "TARGET_PHYLOGENY_FILES ${TARGET_PHYLOGENY_FILES}"
NUM_TARGET_PHYLOGENY_FILES="$(echo ${TARGET_PHYLOGENY_FILES} | wc -w)"
echo "NUM_TARGET_PHYLOGENY_FILES ${NUM_TARGET_PHYLOGENY_FILES}"

for target_phylogeny_file in ${TARGET_PHYLOGENY_FILES}; do
  python3 \
    {% if 'production' == runmode %} -O {% endif %} \
    -c "${PYSCRIPT}" \
    "${target_phylogeny_file}"
  echo "progress step"
done >> >(tqdm \
  --total "${NUM_TARGET_PHYLOGENY_FILES}" \
  --desc "phylogeny file audit completion" \
  --mininterval 10 \
    >> /dev/null \
)

echo "fin ${0}"
